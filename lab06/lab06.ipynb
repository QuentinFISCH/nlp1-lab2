{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import multi30k, Multi30k\n","from typing import Iterable, List\n","\n","\n","# We need to modify the URLs for the dataset since the links to the original dataset are broken\n","# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n","multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n","\n","SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'\n","\n","# Place-holders\n","token_transform = {}\n","vocab_transform = {}"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchdata in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (0.6.1)\n","Requirement already satisfied: requests in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torchdata) (2.28.2)\n","Requirement already satisfied: torch==2.0.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torchdata) (2.0.1)\n","Requirement already satisfied: urllib3>=1.25 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torchdata) (1.26.15)\n","Requirement already satisfied: sympy in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torch==2.0.1->torchdata) (1.11.1)\n","Requirement already satisfied: networkx in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torch==2.0.1->torchdata) (3.0)\n","Requirement already satisfied: jinja2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torch==2.0.1->torchdata) (3.1.2)\n","Requirement already satisfied: typing-extensions in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torch==2.0.1->torchdata) (4.5.0)\n","Requirement already satisfied: filelock in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from torch==2.0.1->torchdata) (3.10.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests->torchdata) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests->torchdata) (3.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests->torchdata) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from jinja2->torch==2.0.1->torchdata) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: spacy in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (3.5.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (1.10.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (2.28.2)\n","Requirement already satisfied: setuptools in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (67.6.0)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (0.7.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (8.1.9)\n","Requirement already satisfied: numpy>=1.15.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (1.24.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (2.4.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (2.0.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (4.65.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (1.0.9)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (3.3.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (6.3.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (1.0.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (1.1.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (3.0.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (2.0.8)\n","Requirement already satisfied: jinja2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (3.1.2)\n","Requirement already satisfied: pathy>=0.10.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy) (23.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from jinja2->spacy) (2.1.2)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting en-core-web-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: pathy>=0.10.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: numpy>=1.15.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: setuptools in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: jinja2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Collecting de-core-news-sm==3.5.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from de-core-news-sm==3.5.0) (3.5.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.12)\n","Requirement already satisfied: jinja2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.4.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.10.6)\n","Requirement already satisfied: packaging>=20.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (23.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.28.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (6.3.0)\n","Requirement already satisfied: pathy>=0.10.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.10.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.9)\n","Requirement already satisfied: setuptools in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (67.6.0)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.1.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.8)\n","Requirement already satisfied: numpy>=1.15.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.24.2)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.65.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.26.15)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/quentinfisch/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.1.2)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n"]}],"source":["%pip install -U torchdata\n","%pip install -U spacy\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'portalocker' is not defined\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m special_symbols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m<unk>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<bos>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<eos>\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m ln \u001b[39min\u001b[39;00m [SRC_LANGUAGE, TGT_LANGUAGE]:\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Training data Iterator\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     train_iter \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(Multi30k(split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, language_pair\u001b[39m=\u001b[39;49m(SRC_LANGUAGE, TGT_LANGUAGE)))\n\u001b[1;32m     20\u001b[0m     \u001b[39m# Create torchtext's Vocab object\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     vocab_transform[ln] \u001b[39m=\u001b[39m build_vocab_from_iterator(yield_tokens(train_iter, ln),\n\u001b[1;32m     22\u001b[0m                                                     min_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                                     specials\u001b[39m=\u001b[39mspecial_symbols,\n\u001b[1;32m     24\u001b[0m                                                     special_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/sharding.py:72\u001b[0m, in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m group_num_of_instances, group_instance_id \u001b[39min\u001b[39;00m sorted_sharding_groups:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstance_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m*\u001b[39m group_instance_id\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_of_instances \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m group_num_of_instances\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:124\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[0;32m--> 124\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    125\u001b[0m             \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:589\u001b[0m, in \u001b[0;36mZipperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[T_co]]:\n\u001b[1;32m    588\u001b[0m     iterators \u001b[39m=\u001b[39m [\u001b[39miter\u001b[39m(datapipe) \u001b[39mfor\u001b[39;00m datapipe \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes]\n\u001b[0;32m--> 589\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39miterators)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/plain_text_reader.py:134\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[39mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    135\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[1;32m    136\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mstrip_newline(stream)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/fileopener.py:67\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/common.py:210\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    208\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 210\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:454\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    455\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    456\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/selecting.py:71\u001b[0m, in \u001b[0;36mFilterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     72\u001b[0m         condition, filtered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returnIfTrue(data)\n\u001b[1;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m condition:\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/tararchiveloader.py:54\u001b[0m, in \u001b[0;36mTarArchiveLoaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, BufferedIOBase]]:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m     55\u001b[0m         validate_pathname_binary_tuple(data)\n\u001b[1;32m     56\u001b[0m         pathname, data_stream \u001b[39m=\u001b[39m data\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/fileopener.py:67\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/common.py:210\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[0;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    208\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m mode\n\u001b[0;32m--> 210\u001b[0m \u001b[39mfor\u001b[39;00m pathname \u001b[39min\u001b[39;00m pathnames:\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(pathname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                         \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:229\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 229\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:374\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    375\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:427\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    428\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_child_stop[instance_id] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:396\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 396\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)\n\u001b[1;32m    397\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier_fn(value)\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:163\u001b[0m, in \u001b[0;36m_ForkerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleading_ptr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchild_pointers[instance_id]\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     return_val \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datapipe_iterator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mappend(return_val)\n\u001b[1;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:52\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m dp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipes:\n\u001b[0;32m---> 52\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dp:\n\u001b[1;32m     53\u001b[0m             \u001b[39myield\u001b[39;00m data\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:454\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[39m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[39m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    455\u001b[0m         rec_uuid, record \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_cell_dp\u001b[39m.\u001b[39mget_last()\n\u001b[1;32m    456\u001b[0m         original_file_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_filepath_fn(record)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mfor\u001b[39;00m filepath, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(filepath)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/hashchecker.py:67\u001b[0m, in \u001b[0;36mHashCheckerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, StreamWrapper]]:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mfor\u001b[39;00m file_name, data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     68\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhash_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msha256\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     69\u001b[0m             hash_func \u001b[39m=\u001b[39m hashlib\u001b[39m.\u001b[39msha256()\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/callable.py:122\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/load/online.py:84\u001b[0m, in \u001b[0;36mHTTPReaderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Tuple[\u001b[39mstr\u001b[39m, StreamWrapper]]:\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m     85\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39myield\u001b[39;00m _get_response_from_http(url, timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_params)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:229\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_caching_flag:\n\u001b[0;32m--> 229\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease call `end_caching()` before iteration.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:374\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[1;32m    375\u001b[0m         item_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_pos \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember_elements\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:144\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_next()\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/_hook_iterator.py:132\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m _check_iterator_valid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator_id)\n\u001b[0;32m--> 132\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_and_has_next_method:\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_dp\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:427\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_next(instance_id)\n\u001b[1;32m    428\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_child_stop[instance_id] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:397\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[0;34m(self, instance_id)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    396\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe_iterator)\n\u001b[0;32m--> 397\u001b[0m classification \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier_fn(value)\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m classification \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_none:\n\u001b[1;32m    399\u001b[0m     StreamWrapper\u001b[39m.\u001b[39mclose_streams(value)\n","File \u001b[0;32m~/Documents/EPITA/ING2/SCIA/S8/NLP1/.venv/lib/python3.9/site-packages/torchdata/datapipes/iter/util/cacheholder.py:262\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe._cache_check_fn\u001b[0;34m(data, filepath_fn, hash_dict, hash_type, extra_check_fn, cache_uuid)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dirname):\n\u001b[1;32m    260\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(dirname)\n\u001b[0;32m--> 262\u001b[0m \u001b[39mwith\u001b[39;00m portalocker\u001b[39m.\u001b[39mLock(promise_filepath, \u001b[39m\"\u001b[39m\u001b[39ma+\u001b[39m\u001b[39m\"\u001b[39m, flags\u001b[39m=\u001b[39mportalocker\u001b[39m.\u001b[39mLockFlags\u001b[39m.\u001b[39mEXCLUSIVE) \u001b[39mas\u001b[39;00m promise_fh:\n\u001b[1;32m    263\u001b[0m     promise_fh\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m    264\u001b[0m     data \u001b[39m=\u001b[39m promise_fh\u001b[39m.\u001b[39mread()\n","\u001b[0;31mNameError\u001b[0m: name 'portalocker' is not defined\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)"]}],"source":["token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","\n","# helper function to yield list of tokens\n","def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    for data_sample in data_iter:\n","        yield token_transform[language](data_sample[language_index[language]])\n","\n","# Define special symbols and indices\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","# Make sure the tokens are in order of their indices to properly insert them in vocab\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    # Training data Iterator\n","    train_iter = list(Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)))\n","    # Create torchtext's Vocab object\n","    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n","                                                    min_freq=1,\n","                                                    specials=special_symbols,\n","                                                    special_first=True)\n","\n","# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n","# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","  vocab_transform[ln].set_default_index(UNK_IDX)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["import torch\n","for s in iter(train_iter):\n","    print(s)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.nn import Transformer\n","import math\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n","class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","# Seq2Seq Network\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 128\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(DEVICE)\n","\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","# helper function to club together sequential operations\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# function to add BOS/EOS and create tensor for input sequence indices\n","def tensor_transform(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n","                                               vocab_transform[ln], #Numericalization\n","                                               tensor_transform) # Add BOS/EOS and create tensor\n","\n","\n","# function to collate data samples into batch tensors\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def train_epoch(model, optimizer):\n","    model.train()\n","    losses = 0\n","    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in train_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        optimizer.zero_grad()\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(list(train_dataloader))\n","\n","\n","def evaluate(model):\n","    model.eval()\n","    losses = 0\n","\n","    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in val_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","\n","    return losses / len(list(val_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from timeit import default_timer as timer\n","NUM_EPOCHS = 18\n","\n","for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = timer()\n","    train_loss = train_epoch(transformer, optimizer)\n","    end_time = timer()\n","    val_loss = evaluate(transformer)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","\n","# function to generate output sequence using greedy algorithm\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","# actual function to translate input sentence into target language\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Theoritical questions answer\n","\n","* In the positional encoding, why are we using a combination of sinus and cosinus?\n","* In the Seq2SeqTransformer class,\n","    * What is the parameter nhead for?\n","    * What is the point of the generator?\n","* Describe the goal of the create_mask function. Why does it handle differently the source and target masks?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### In the positional encoding, why are we using a combination of sinus and cosinus?\n","\n","The positional encoding is a way to encode the position of the words in the sentence. We use sinus and cosinus because they are orthogonal and they can encode the position of the words in the sentence.\n","\n","#### In the Seq2SeqTransformer class, What is the parameter nhead for?\n","\n","The parameter nhead is the number of heads in the multihead attention. It is the number of parallel attention layers. It is used to increase the representational power of the model.\n","\n","#### In the Seq2SeqTransformer class, What is the point of the generator?\n","\n","The generator is a linear layer that takes the output of the decoder and returns the logits. It maps the output of the decoder to the vocabulary.\n","\n","#### Describe the goal of the create_mask function. Why does it handle differently the source and target masks?\n","\n","The goal of the create_mask function is to create a mask for the source and the target. The source mask is used to mask the padding tokens. The target mask is used to mask the padding tokens and the future tokens."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Decoding functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Implement a top-k sampling with temperature decoding function\n","\n","def top_k_sampling_with_temperature(model, src, src_mask, max_len, start_symbol, k, temperature):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        prob = torch.div(prob, temperature)\n","        prob = torch.softmax(prob, dim=1)\n","        top_k_prob, top_k_idx = torch.topk(prob, k=k, dim=1)\n","        next_word = torch.multinomial(top_k_prob, num_samples=1)\n","        next_word = top_k_idx[torch.arange(top_k_idx.size(0)), next_word.squeeze(1)]\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate_top_k(model: torch.nn.Module, src_sentence: str, k, temperature):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = top_k_sampling_with_temperature(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, k=k, temperature=temperature).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Implement a top-p sampling with temperature decoding function\n","\n","def top_p_sampling_with_temperature(model, src, src_mask, max_len, start_symbol, p, temperature):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        prob = torch.div(prob, temperature)\n","        prob = torch.softmax(prob, dim=1)\n","        sorted_prob, sorted_idx = torch.sort(prob, descending=True, dim=1)\n","        cumulative_prob = torch.cumsum(sorted_prob, dim=1)\n","        sorted_idx_to_remove = cumulative_prob > p\n","        sorted_idx_to_remove[:, 1:] = sorted_idx_to_remove[:, :-1].clone()\n","        sorted_idx_to_remove[:, 0] = 0\n","        sorted_idx_to_remove = sorted_idx_to_remove.type(torch.bool)\n","        sorted_idx[sorted_idx_to_remove] = -1\n","        sorted_idx[sorted_idx != -1] = 0\n","        sorted_idx[sorted_idx == -1] = 1\n","        sorted_idx = sorted_idx.type(torch.bool)\n","        next_word = torch.multinomial(sorted_idx, num_samples=1)\n","        next_word = sorted_idx[torch.arange(sorted_idx.size(0)), next_word.squeeze(1)]\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","def translate_top_p(model: torch.nn.Module, src_sentence: str, p, temperature):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = top_p_sampling_with_temperature(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, p=p, temperature=temperature).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Play with the k, p and temperature parameters, and qualitatively compare a few (at least 3) translation samples for each approach (even the greedy one).\n","\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=5, temperature=1.0))\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=5, temperature=0.5))\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=5, temperature=0.1))\n","\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.9, temperature=1.0))\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.9, temperature=0.5))\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.9, temperature=0.1))\n","\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=10, temperature=1.0))\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=10, temperature=0.5))\n","print(translate_top_k(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", k=10, temperature=0.1))\n","\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.8, temperature=1.0))\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.8, temperature=0.5))\n","print(translate_top_p(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", p=0.8, temperature=0.1))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Compute the BLEU score of the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use the sacreBLEU implementation to evaluate your model and quantitatively compare the 4 implemented decoding approaches on the test set. Explain what all the output values mean (when using the corpus_score function).\n","\n","from torchtext.data.metrics import bleu_score\n","\n","def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n","    trgs = []\n","    pred_trgs = []\n","    for datum in data:\n","        src = vars(datum)['src']\n","        trg = vars(datum)['trg']\n","        pred_trg = translate(model, src)\n","        #cut off <eos> token\n","        pred_trg = pred_trg[:-4]\n","        pred_trgs.append(pred_trg.split())\n","        trgs.append([trg.split()])\n","    return bleu_score(pred_trgs, trgs)\n","\n","def calculate_bleu_top_k(data, src_field, trg_field, model, device, k, temperature, max_len = 50):\n","    trgs = []\n","    pred_trgs = []\n","    for datum in data:\n","        src = vars(datum)['src']\n","        trg = vars(datum)['trg']\n","        pred_trg = translate_top_k(model, src, k=k, temperature=temperature)\n","        #cut off <eos> token\n","        pred_trg = pred_trg[:-4]\n","        pred_trgs.append(pred_trg.split())\n","        trgs.append([trg.split()])\n","    return bleu_score(pred_trgs, trgs)\n","\n","def calculate_bleu_top_p(data, src_field, trg_field, model, device, p, temperature, max_len = 50):\n","    trgs = []\n","    pred_trgs = []\n","    for datum in data:\n","        src = vars(datum)['src']\n","        trg = vars(datum)['trg']\n","        pred_trg = translate_top_p(model, src, p=p, temperature=temperature)\n","        #cut off <eos> token\n","        pred_trg = pred_trg[:-4]\n","        pred_trgs.append(pred_trg.split())\n","        trgs.append([trg.split()])\n","    return bleu_score(pred_trgs, trgs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_iter = Multi30k(split='test', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","bleu_score = calculate_bleu(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","\n","bleu_score = calculate_bleu_top_k(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, k=5, temperature=1.0)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","bleu_score = calculate_bleu_top_k(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, k=5, temperature=0.5)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","bleu_score = calculate_bleu_top_k(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, k=5, temperature=0.1)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","\n","bleu_score = calculate_bleu_top_p(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, p=0.9, temperature=1.0)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","bleu_score = calculate_bleu_top_p(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, p=0.9, temperature=0.5)\n","print(f'BLEU score = {bleu_score*100:.2f}')\n","bleu_score = calculate_bleu_top_p(test_iter, SRC_LANGUAGE, TGT_LANGUAGE, transformer, DEVICE, p=0.9, temperature=0.1)\n","print(f'BLEU score = {bleu_score*100:.2f}')"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
