{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_split_names\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/quentinfisch/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 96.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def preprocess(dataset: pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by lowercasing the text and removing the punctuation manually\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        The dataset to preprocess\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The preprocessed dataset\n",
    "    \"\"\"\n",
    "    # First lower the case\n",
    "    dataset[\"document\"] = dataset[\"document\"].apply(lambda x: x.lower())\n",
    "    # Replace the punctuation with spaces. We keep the ' - that may give revelant informations\n",
    "    # Replace HTML tag <br />\n",
    "    punctuation_to_remove = '|'.join(map(re.escape, sorted(list(filter(lambda p: p != \"'\" and p != '-' and p != \"!\", punctuation)), reverse=True)))\n",
    "    print(f\"Deleting all these punctuation: {punctuation_to_remove}\")\n",
    "    dataset[\"document\"] = dataset[\"document\"].apply(lambda x: re.sub(punctuation_to_remove, \" \", x.replace('<br />', \"\")))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all these punctuation: \\~|\\}|\\||\\{|`|_|\\^|\\]|\\\\|\\[|@|\\?|>|=|<|;|:|/|\\.|,|\\+|\\*|\\)|\\(|\\&|%|\\$|\\#|\"\n",
      "Deleting all these punctuation: \\~|\\}|\\||\\{|`|_|\\^|\\]|\\\\|\\[|@|\\?|>|=|<|;|:|/|\\.|,|\\+|\\*|\\)|\\(|\\&|%|\\$|\\#|\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worth the entertainment value of a rental  esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star rating        saturday night      friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first off let me say  if you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>just got around to seeing monster man yesterda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>i got this as part of a competition prize  i w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>i got monster man in a box set of three films ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>five minutes in  i started to feel how naff th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>i caught this movie on the sci-fi channel rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  class\n",
       "0      i love sci-fi and am willing to put up with a ...      0\n",
       "1      worth the entertainment value of a rental  esp...      0\n",
       "2      its a totally average film with a few semi-alr...      0\n",
       "3      star rating        saturday night      friday ...      0\n",
       "4      first off let me say  if you haven't enjoyed a...      0\n",
       "...                                                  ...    ...\n",
       "24995  just got around to seeing monster man yesterda...      1\n",
       "24996  i got this as part of a competition prize  i w...      1\n",
       "24997  i got monster man in a box set of three films ...      1\n",
       "24998  five minutes in  i started to feel how naff th...      1\n",
       "24999  i caught this movie on the sci-fi channel rece...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.DataFrame(dataset[\"train\"], columns=[\"text\", \"label\"]).rename(columns={\"text\": \"document\", \"label\": \"class\"})\n",
    "preprocessed_train = preprocess(train_raw)\n",
    "preprocessed_train\n",
    "\n",
    "test_raw = pd.DataFrame(dataset[\"test\"], columns=[\"text\", \"label\"]).rename(columns={\"text\": \"document\", \"label\": \"class\"})\n",
    "preprocessed_test = preprocess(test_raw)\n",
    "preprocessed_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load lexicon and keep only interesting tokens (one above the treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$:</th>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%-)</th>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( '}{' )</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('-:</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(':</th>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|^:</th>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>||-:</th>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:</th>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:(</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:-(</th>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5830 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score\n",
       "Token          \n",
       "$:         -1.5\n",
       "%-)        -1.5\n",
       "( '}{' )    1.6\n",
       "('-:        2.2\n",
       "(':         2.3\n",
       "...         ...\n",
       "|^:        -1.1\n",
       "||-:       -2.3\n",
       "}:         -2.1\n",
       "}:(        -2.0\n",
       "}:-(       -2.1\n",
       "\n",
       "[5830 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treshhold = 1\n",
    "lexicon = pd.read_csv(\"vader_lexicon.txt\", sep=\"\\t\", names=['Token', \"Score\", \"Std\", \"Vector\"]).drop(columns=[\"Std\", \"Vector\"]).set_index(\"Token\")\n",
    "lexicon = lexicon[(lexicon[\"Score\"] <= -treshhold) | (lexicon[\"Score\"] >= treshhold)]\n",
    "lexicon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the following features:\n",
    "- 1 if \"no\" appears in the document, 0 otherwise.\n",
    "- The count of first and second pronouns in the document.\n",
    "- 1 if \"!\" is in the document, 0 otherwise.\n",
    "- Log(word count in the document).\n",
    "- Number of words in the document which are in the positive lexicon.\n",
    "- Number of words in the document which are in the negative lexicon.\n",
    "- [Bonus] Add another feature of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the following features:\n",
    "# - 1 if \"no\" appears in the document, 0 otherwise.\n",
    "# - The count of first and second pronouns in the document.\n",
    "# - 1 if \"!\" is in the document, 0 otherwise.\n",
    "# - Log(word count in the document).\n",
    "# - Number of words in the document which are in the positive lexicon.\n",
    "# - Number of words in the document which are in the negative lexicon.\n",
    "# - [Bonus] Add another feature of your choice.\n",
    "\n",
    "def is_in_lexicon(word: str, positive: bool):\n",
    "    try:\n",
    "        score = lexicon.at[word, \"Score\"].item()\n",
    "        if positive:\n",
    "            return score >= treshhold\n",
    "        else:\n",
    "            return score <= -treshhold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def generate_features(dataset: pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Generate the features for the dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        The dataset to generate the features for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataset with the features\n",
    "    \"\"\"\n",
    "    dataset[\"no\"] = dataset[\"document\"].apply(lambda x: 1 if \"no\" in x.split(\" \") else 0)\n",
    "    dataset[\"pronouns\"] = dataset[\"document\"].apply(lambda x: x.split(\" \")).apply(lambda x: x.count(\"i\") + x.count(\"me\") + x.count(\"my\") + x.count(\"mine\") + x.count(\"we\") + x.count(\"us\") + x.count(\"our\") + x.count(\"ours\") + x.count(\"you\") + x.count(\"your\") + x.count(\"yours\") + x.count(\"u\") + x.count(\"ur\") + x.count(\"urs\"))\n",
    "    dataset[\"exclamation\"] = dataset[\"document\"].apply(lambda x: 1 if \"!\" in x else 0)\n",
    "    dataset[\"log_word_count\"] = dataset[\"document\"].apply(lambda x: np.log(len(x.split(\" \"))))\n",
    "    dataset[\"positive_lexicon\"] = dataset[\"document\"].apply(lambda x: len(list(filter(lambda w: is_in_lexicon(w, True), x.split(\" \")))))\n",
    "    dataset[\"negative_lexicon\"] = dataset[\"document\"].apply(lambda x: len(list(filter(lambda w: is_in_lexicon(w, False), x.split(\" \")))))\n",
    "\n",
    "    # add feature vector column\n",
    "    dataset[\"feature_vector\"] = dataset.apply(lambda x: [x[\"no\"], x[\"pronouns\"], x[\"exclamation\"], x[\"log_word_count\"], x[\"positive_lexicon\"], x[\"negative_lexicon\"]], axis=1)\n",
    "    # drop the other columns\n",
    "    dataset = dataset.drop(columns=[\"no\", \"pronouns\", \"exclamation\", \"log_word_count\", \"positive_lexicon\", \"negative_lexicon\"])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curious-yellow from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 11, 0, 5.739792912179234, 7, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>i saw this film opening weekend in australia  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 8, 0, 5.402677381872279, 15, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>terrible movie  nuff said these lines are just...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 10, 0, 5.123963979403259, 3, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>this film is a calculated attempt to cash in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 2, 0, 5.209486152841421, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>this is an action western  james steart leads ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 5.19295685089021, 14, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24750</th>\n",
       "      <td>this could be well have been the definitive fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4, 1, 6.792344427470809, 45, 22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24800</th>\n",
       "      <td>you'd be forgiven to think a finnish director ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 5, 1, 5.308267697401205, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24850</th>\n",
       "      <td>a tragically wonderful movie    brings us to a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 5, 0, 5.081404364984463, 6, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24900</th>\n",
       "      <td>i can't remember many films where a bumbling i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 2, 0, 4.189654742026425, 6, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>i definitely recommend reading the book prior ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 6, 1, 5.703782474656201, 14, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  class  \\\n",
       "0      i rented i am curious-yellow from my video sto...      0   \n",
       "50     i saw this film opening weekend in australia  ...      0   \n",
       "100    terrible movie  nuff said these lines are just...      0   \n",
       "150    this film is a calculated attempt to cash in t...      0   \n",
       "200    this is an action western  james steart leads ...      0   \n",
       "...                                                  ...    ...   \n",
       "24750  this could be well have been the definitive fi...      1   \n",
       "24800  you'd be forgiven to think a finnish director ...      1   \n",
       "24850  a tragically wonderful movie    brings us to a...      1   \n",
       "24900  i can't remember many films where a bumbling i...      1   \n",
       "24950  i definitely recommend reading the book prior ...      1   \n",
       "\n",
       "                             feature_vector  \n",
       "0       [1, 11, 0, 5.739792912179234, 7, 6]  \n",
       "50      [0, 8, 0, 5.402677381872279, 15, 4]  \n",
       "100    [0, 10, 0, 5.123963979403259, 3, 13]  \n",
       "150      [0, 2, 0, 5.209486152841421, 5, 4]  \n",
       "200      [0, 0, 0, 5.19295685089021, 14, 4]  \n",
       "...                                     ...  \n",
       "24750  [0, 4, 1, 6.792344427470809, 45, 22]  \n",
       "24800    [1, 5, 1, 5.308267697401205, 5, 6]  \n",
       "24850    [0, 5, 0, 5.081404364984463, 6, 1]  \n",
       "24900    [0, 2, 0, 4.189654742026425, 6, 2]  \n",
       "24950   [0, 6, 1, 5.703782474656201, 14, 3]  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_train = preprocessed_train.iloc[::50].copy()\n",
    "\n",
    "reduced_train = generate_features(reduced_train)\n",
    "reduced_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
