{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/quentinfisch/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 88.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def preprocess(dataset: pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by lowercasing the text and removing the punctuation manually\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        The dataset to preprocess\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The preprocessed dataset\n",
    "    \"\"\"\n",
    "    # First lower the case\n",
    "    dataset[\"document\"] = dataset[\"document\"].apply(lambda x: x.lower())\n",
    "    # Replace the punctuation with spaces. We keep the ' - that may give revelant informations\n",
    "    # Replace HTML tag <br />\n",
    "    punctuation_to_remove = '|'.join(map(re.escape, sorted(list(filter(lambda p: p != \"'\" and p != '-' and p != \"!\", punctuation)), reverse=True)))\n",
    "    print(f\"Deleting all these punctuation: {punctuation_to_remove}\")\n",
    "    dataset[\"document\"] = dataset[\"document\"].apply(lambda x: re.sub(punctuation_to_remove, \" \", x.replace('<br />', \"\")))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all these punctuation: \\~|\\}|\\||\\{|`|_|\\^|\\]|\\\\|\\[|@|\\?|>|=|<|;|:|/|\\.|,|\\+|\\*|\\)|\\(|\\&|%|\\$|\\#|\"\n",
      "Deleting all these punctuation: \\~|\\}|\\||\\{|`|_|\\^|\\]|\\\\|\\[|@|\\?|>|=|<|;|:|/|\\.|,|\\+|\\*|\\)|\\(|\\&|%|\\$|\\#|\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                document  class\n",
       " 0      i rented i am curious-yellow from my video sto...      0\n",
       " 1       i am curious  yellow  is a risible and preten...      0\n",
       " 2      if only to avoid making this type of film in t...      0\n",
       " 3      this film was probably inspired by godard's ma...      0\n",
       " 4      oh  brother   after hearing about this ridicul...      0\n",
       " ...                                                  ...    ...\n",
       " 24995  a hit at the time but now better categorised a...      1\n",
       " 24996  i love this movie like no other  another time ...      1\n",
       " 24997  this film and it's sequel barry mckenzie holds...      1\n",
       " 24998  'the adventures of barry mckenzie' started lif...      1\n",
       " 24999  the story centers around barry mckenzie who mu...      1\n",
       " \n",
       " [25000 rows x 2 columns],\n",
       "                                                 document  class\n",
       " 0      i love sci-fi and am willing to put up with a ...      0\n",
       " 1      worth the entertainment value of a rental  esp...      0\n",
       " 2      its a totally average film with a few semi-alr...      0\n",
       " 3      star rating        saturday night      friday ...      0\n",
       " 4      first off let me say  if you haven't enjoyed a...      0\n",
       " ...                                                  ...    ...\n",
       " 24995  just got around to seeing monster man yesterda...      1\n",
       " 24996  i got this as part of a competition prize  i w...      1\n",
       " 24997  i got monster man in a box set of three films ...      1\n",
       " 24998  five minutes in  i started to feel how naff th...      1\n",
       " 24999  i caught this movie on the sci-fi channel rece...      1\n",
       " \n",
       " [25000 rows x 2 columns])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.DataFrame(dataset[\"train\"], columns=[\"text\", \"label\"]).rename(columns={\"text\": \"document\", \"label\": \"class\"})\n",
    "preprocessed_train = preprocess(train_raw)\n",
    "\n",
    "test_raw = pd.DataFrame(dataset[\"test\"], columns=[\"text\", \"label\"]).rename(columns={\"text\": \"document\", \"label\": \"class\"})\n",
    "preprocessed_test = preprocess(test_raw)\n",
    "preprocessed_train, preprocessed_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load lexicon and keep only interesting tokens (one above the treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$:</th>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%-)</th>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( '}{' )</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>('-:</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(':</th>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>|^:</th>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>||-:</th>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:</th>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:(</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>}:-(</th>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5830 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score\n",
       "Token          \n",
       "$:         -1.5\n",
       "%-)        -1.5\n",
       "( '}{' )    1.6\n",
       "('-:        2.2\n",
       "(':         2.3\n",
       "...         ...\n",
       "|^:        -1.1\n",
       "||-:       -2.3\n",
       "}:         -2.1\n",
       "}:(        -2.0\n",
       "}:-(       -2.1\n",
       "\n",
       "[5830 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 1\n",
    "lexicon = pd.read_csv(\"vader_lexicon.txt\", sep=\"\\t\", names=['Token', \"Score\", \"Std\", \"Vector\"]).drop(columns=[\"Std\", \"Vector\"]).set_index(\"Token\")\n",
    "lexicon = lexicon[(lexicon[\"Score\"] <= -threshold) | (lexicon[\"Score\"] >= threshold)]\n",
    "lexicon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the following features:\n",
    "- 1 if \"no\" appears in the document, 0 otherwise.\n",
    "- The count of first and second pronouns in the document.\n",
    "- 1 if \"!\" is in the document, 0 otherwise.\n",
    "- Log(word count in the document).\n",
    "- Number of words in the document which are in the positive lexicon.\n",
    "- Number of words in the document which are in the negative lexicon.\n",
    "- [Bonus] Add another feature of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the following features:\n",
    "# - 1 if \"no\" appears in the document, 0 otherwise.\n",
    "# - The count of first and second pronouns in the document.\n",
    "# - 1 if \"!\" is in the document, 0 otherwise.\n",
    "# - Log(word count in the document).\n",
    "# - Number of words in the document which are in the positive lexicon.\n",
    "# - Number of words in the document which are in the negative lexicon.\n",
    "# - [Bonus] Add another feature of your choice.\n",
    "\n",
    "def is_in_lexicon(word: str, positive: bool):\n",
    "    try:\n",
    "        score = lexicon.at[word, \"Score\"].item()\n",
    "        return score >= threshold if positive else score <= -threshold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def generate_features(dataset: pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Generate the features for the dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        The dataset to generate the features for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataset with the features\n",
    "    \"\"\"\n",
    "    dataset[\"no\"] = dataset[\"document\"].apply(lambda x: 1 if \"no\" in x.split(\" \") else 0)\n",
    "    dataset[\"pronouns\"] = dataset[\"document\"].apply(lambda x: x.split(\" \")).apply(lambda x: x.count(\"i\") + x.count(\"we\") + x.count(\"you\"))\n",
    "    dataset[\"exclamation\"] = dataset[\"document\"].apply(lambda x: 1 if \"!\" in x else 0)\n",
    "    dataset[\"log_word_count\"] = dataset[\"document\"].apply(lambda x: np.log(len(x.split(\" \"))))\n",
    "    dataset[\"positive_lexicon\"] = dataset[\"document\"].apply(lambda x: len(list(filter(lambda w: is_in_lexicon(w, True), x.split(\" \")))))\n",
    "    dataset[\"negative_lexicon\"] = dataset[\"document\"].apply(lambda x: len(list(filter(lambda w: is_in_lexicon(w, False), x.split(\" \")))))\n",
    "\n",
    "    # add feature vector column\n",
    "    dataset[\"feature_vector\"] = dataset.apply(lambda x: [x[\"no\"], x[\"pronouns\"], x[\"exclamation\"], x[\"log_word_count\"], x[\"positive_lexicon\"], x[\"negative_lexicon\"]], axis=1)\n",
    "    # drop the other columns\n",
    "    dataset = dataset.drop(columns=[\"no\", \"pronouns\", \"exclamation\", \"log_word_count\", \"positive_lexicon\", \"negative_lexicon\"])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curious-yellow from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 11, 0, 5.739792912179234, 7, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>it was great to see some of my favorite stars ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 9, 0, 5.680172609017068, 14, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>if the crew behind  zombie chronicles  ever re...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 9, 0, 5.327876168789581, 9, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>i have not seen many low budget films i must a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 7, 0, 5.209486152841421, 8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i have read all of the love come softly books ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 0, 5.0106352940962555, 5, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>i definitely recommend reading the book prior ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 6, 1, 5.703782474656201, 14, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24960</th>\n",
       "      <td>i used to watch this show when i was a little ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 14, 0, 5.123963979403259, 9, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>i've seen this movie and i must say i'm very i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 13, 0, 5.0689042022202315, 13, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>i was pleased to see that she had black hair! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 8, 1, 5.049856007249537, 9, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>like i said its a hidden surprise  it well wri...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4, 0, 4.127134385045092, 9, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  class  \\\n",
       "0      i rented i am curious-yellow from my video sto...      0   \n",
       "10     it was great to see some of my favorite stars ...      0   \n",
       "20     if the crew behind  zombie chronicles  ever re...      0   \n",
       "30     i have not seen many low budget films i must a...      0   \n",
       "40     i have read all of the love come softly books ...      0   \n",
       "...                                                  ...    ...   \n",
       "24950  i definitely recommend reading the book prior ...      1   \n",
       "24960  i used to watch this show when i was a little ...      1   \n",
       "24970  i've seen this movie and i must say i'm very i...      1   \n",
       "24980  i was pleased to see that she had black hair! ...      1   \n",
       "24990  like i said its a hidden surprise  it well wri...      1   \n",
       "\n",
       "                              feature_vector  \n",
       "0        [1, 11, 0, 5.739792912179234, 7, 6]  \n",
       "10       [1, 9, 0, 5.680172609017068, 14, 4]  \n",
       "20        [1, 9, 0, 5.327876168789581, 9, 2]  \n",
       "30        [0, 7, 0, 5.209486152841421, 8, 7]  \n",
       "40       [0, 5, 0, 5.0106352940962555, 5, 3]  \n",
       "...                                      ...  \n",
       "24950    [0, 6, 1, 5.703782474656201, 14, 3]  \n",
       "24960    [0, 14, 0, 5.123963979403259, 9, 0]  \n",
       "24970  [0, 13, 0, 5.0689042022202315, 13, 2]  \n",
       "24980     [0, 8, 1, 5.049856007249537, 9, 3]  \n",
       "24990     [0, 4, 0, 4.127134385045092, 9, 0]  \n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_train = preprocessed_train.iloc[::10].copy()\n",
    "reduced_train = generate_features(reduced_train)\n",
    "reduced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 5, 1, 5.62040086571715, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>this flick is a waste of time i expect from an...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 0, 4.948759890378168, 3, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>low budget horror movie  if you don't raise yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 6, 1, 5.225746673713202, 10, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lowe returns to the nest after  yet another  f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 1, 5.459585514144159, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>i can't believe the high marks people have giv...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 6, 1, 5.6240175061873385, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24950</th>\n",
       "      <td>especially by lambert  this is the essential...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 8, 0, 5.10594547390058, 8, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24960</th>\n",
       "      <td>watch it with an open mind  it is very differe...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 4.02535169073515, 4, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>slipknot is a heavy metal band from the great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 8, 0, 5.117993812416755, 6, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>this film is just plain lovely  it's funny as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 3, 1, 4.912654885736052, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>i first saw this on demand  or on tv  i'm not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 9, 1, 4.969813299576001, 10, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  class  \\\n",
       "0      i love sci-fi and am willing to put up with a ...      0   \n",
       "10     this flick is a waste of time i expect from an...      0   \n",
       "20     low budget horror movie  if you don't raise yo...      0   \n",
       "30     lowe returns to the nest after  yet another  f...      0   \n",
       "40     i can't believe the high marks people have giv...      0   \n",
       "...                                                  ...    ...   \n",
       "24950    especially by lambert  this is the essential...      1   \n",
       "24960  watch it with an open mind  it is very differe...      1   \n",
       "24970  slipknot is a heavy metal band from the great ...      1   \n",
       "24980  this film is just plain lovely  it's funny as ...      1   \n",
       "24990  i first saw this on demand  or on tv  i'm not ...      1   \n",
       "\n",
       "                            feature_vector  \n",
       "0        [0, 5, 1, 5.62040086571715, 9, 8]  \n",
       "10     [1, 1, 0, 4.948759890378168, 3, 12]  \n",
       "20     [0, 6, 1, 5.225746673713202, 10, 7]  \n",
       "30      [0, 4, 1, 5.459585514144159, 8, 9]  \n",
       "40     [0, 6, 1, 5.6240175061873385, 8, 9]  \n",
       "...                                    ...  \n",
       "24950    [0, 8, 0, 5.10594547390058, 8, 3]  \n",
       "24960    [0, 1, 0, 4.02535169073515, 4, 0]  \n",
       "24970   [0, 8, 0, 5.117993812416755, 6, 1]  \n",
       "24980   [0, 3, 1, 4.912654885736052, 5, 2]  \n",
       "24990  [0, 9, 1, 4.969813299576001, 10, 0]  \n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_test = preprocessed_test.iloc[::10].copy()\n",
    "\n",
    "reduced_test = generate_features(reduced_test)\n",
    "reduced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set generated\n",
      "Test set generated\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = generate_features(preprocessed_train)\n",
    "print(\"Train set generated\")\n",
    "preprocessed_test = generate_features(preprocessed_test)\n",
    "print(\"Test set generated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \"\"\"A linear regression implementation\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, nb_classes: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: the dimension of the input features.\n",
    "            nb_classes: the number of classes to predict.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, nb_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: the input tensor.\n",
    "        Returns:\n",
    "            The output of the linear layer.\n",
    "        \"\"\"\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(6, 1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21250, 6]),\n",
       " torch.Size([3750, 6]),\n",
       " torch.Size([21250, 1]),\n",
       " torch.Size([3750, 1]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train = preprocessed_train[\"feature_vector\"]\n",
    "# convert to numpy array 2d\n",
    "features_train = np.array(features_train.to_list())\n",
    "labels_train = preprocessed_train[\"class\"].to_numpy()\n",
    "\n",
    "features_train = torch.tensor(features_train, dtype=torch.float32)\n",
    "labels_train = torch.tensor(labels_train, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    features_train,\n",
    "    labels_train,\n",
    "    test_size=0.15,\n",
    "    stratify=labels_train,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25000, 6]), torch.Size([25000, 1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the same feature engineering for the test set\n",
    "features_test = preprocessed_test[\"feature_vector\"]\n",
    "features_test = np.array(features_test.to_list())\n",
    "X_test = torch.tensor(features_test, dtype=torch.float32)\n",
    "\n",
    "labels_test = preprocessed_test[\"class\"].to_numpy()\n",
    "y_test = torch.tensor(labels_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8912, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5868, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5859, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5853, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5850, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5849, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5848, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5848, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5848, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5848, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "CPU times: user 680 ms, sys: 176 ms, total: 856 ms\n",
      "Wall time: 597 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "# Keeping an eye on the losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # Setting all gradients to zero.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sending the whole training set through the model.\n",
    "    predictions = model(X_train)\n",
    "    # Computing the loss.\n",
    "    loss = criterion(predictions, y_train)\n",
    "    train_losses.append(loss.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)\n",
    "    # Computing the gradients and gradient descent.\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # When computing the validation loss, we do not want to update the weights.\n",
    "    # torch.no_grad tells PyTorch to not save the necessary data used for\n",
    "    # gradient descent.\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_valid)\n",
    "        loss = criterion(predictions, y_valid)\n",
    "        test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28828af10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(train_losses)), train_losses, label=\"Training loss\")\n",
    "plt.plot(np.arange(len(test_losses)), test_losses, label=\"Test loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152 0.7 0.71408\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    p_train = torch.sigmoid(model(X_train))\n",
    "    p_train = np.round(p_train.numpy())\n",
    "    training_accuracy = np.mean(p_train == y_train.numpy())\n",
    "    p_valid = torch.sigmoid(model(X_valid))\n",
    "    p_valid = np.round(p_valid.numpy())\n",
    "    valid_accuracy = np.mean(p_valid == y_valid.numpy())\n",
    "    p_test = torch.sigmoid(model(X_test))\n",
    "    p_test = np.round(p_test.numpy())\n",
    "    test_accuracy = np.mean(p_test == y_test.numpy())\n",
    "print(training_accuracy, valid_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02932489 -0.02839465 -0.00931369 -0.02108636  0.12831183 -0.15112449]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Look at the weights of your classifier. Which features seems to play most for both classes ?\n",
    "\n",
    "# Let's look at the weights of the linear layer\n",
    "weights = model.linear.weight.detach().numpy()\n",
    "print(weights)\n",
    "print(np.argmax(weights))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature playing the most important role in the classification is the number of words in the document which are in the positive lexicon. This is not surprising as the positive lexicon contains words such as \"good\", \"great\", \"excellent\", etc. which are very indicative of a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    4     6    11 ... 24991 24998 24999]\n",
      "first off let me say  if you haven't enjoyed a van damme movie since bloodsport  you probably will not like this movie  most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are  this movie is much better than any of the movies the other action guys  segal and dolph  have thought about putting out the past few years  van damme is good in the movie  the movie is only worth watching to van damme fans  it is not as good as wake of death  which i highly recommend to anyone of likes van damme  or in hell but  in my opinion it's worth watching  it has the same type of feel to it as nowhere to run  good fun stuff!\n",
      "document          first off let me say  if you haven't enjoyed a...\n",
      "class                                                             0\n",
      "feature_vector                  [0, 6, 1, 4.997212273764115, 12, 2]\n",
      "Name: 4, dtype: object\n",
      "isaac florentine has made some of the best western martial arts action movies ever produced  in particular us seals 2  cold harvest  special forces and undisputed 2 are all action classics  you can tell isaac has a real passion for the genre and his films are always eventful  creative and sharp affairs  with some of the best fight sequences an action fan could hope for  in particular he has found a muse with scott adkins  as talented an actor and action performer as you could hope for  this is borne out with special forces and undisputed 2  but unfortunately the shepherd just doesn't live up to their abilities there is no doubt that jcvd looks better here fight-wise than he has done in years  especially in the fight he has  for pretty much no reason  in a prison cell  and in the final showdown with scott  but look in his eyes  jcvd seems to be dead inside  there's nothing in his eyes at all  it's like he just doesn't care about anything throughout the whole film  and this is the leading man there are other dodgy aspects to the film  script-wise and visually  but the main problem is that you are utterly unable to empathise with the hero of the film  a genuine shame as i know we all wanted this film to be as special as it genuinely could have been  there are some good bits  mostly the action scenes themselves  this film had a terrific director and action choreographer  and an awesome opponent for jcvd to face down  this could have been the one to bring the veteran action star back up to scratch in the balls-out action movie stakes sincerely a shame that this didn't happen \n",
      "document          isaac florentine has made some of the best wes...\n",
      "class                                                             0\n",
      "feature_vector                  [1, 6, 0, 5.75890177387728, 21, 11]\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Take two wrongly classified samples in the test set and try explaining why the model was wrong.\n",
    "\n",
    "# Let's look at the wrongly classified samples\n",
    "wrongly_classified = np.where(p_test != y_test.numpy())[0]\n",
    "print(wrongly_classified)\n",
    "\n",
    "# Let's look at the first wrongly classified sample\n",
    "print(preprocessed_test.iloc[wrongly_classified[0]][\"document\"], preprocessed_test.iloc[wrongly_classified[0]], sep=\"\\n\")\n",
    "\n",
    "# Let's look at the second wrongly classified sample\n",
    "print(preprocessed_test.iloc[wrongly_classified[1]][\"document\"], preprocessed_test.iloc[wrongly_classified[1]], sep=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These wrondly classified examples are mostly positive reviews which are classified as negative. This is surely because they are really hard to classify, mixing positive and negative parts. In the first one: 'if you haven't enjoyed a van damme movie since bloodsport you probably will not like this movie' is negative when read on its own, but positive when read in the context of the whole review. The second one also contains negative or mixed parts inside the whole review, which is very confusing for the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
