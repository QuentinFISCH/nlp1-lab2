{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import fasttext as ft\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eba430ba3c0400495f64142185cc187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/nicolas/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472940f741974fb0a0b1dd404e1b8bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "\n",
    "## 1. Turn the dataset into a dataset compatible with Fastext (see the Tips on using FastText section a bit lower).\n",
    "\n",
    "For pretreatment, only apply lower casing and punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by lowercasing the text and removing the punctuation manually\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataset to preprocess\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The preprocessed dataset with added \"__label__\" prefix to \"class\" column and cleaned \"document\" column.    \n",
    "    \"\"\"\n",
    "    punctuation_to_remove = \"|\".join(\n",
    "        map(\n",
    "            re.escape,\n",
    "            sorted(\n",
    "                list(filter(lambda p: p != \"'\" and p != \"-\", punctuation)), reverse=True\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    df[\"class\"] = df[\"class\"].apply(\n",
    "        lambda x: \"__label__\" + (\"positive\" if x == 0 else \"negative\")\n",
    "    )\n",
    "    df[\"document\"] = (\n",
    "        df[\"class\"]\n",
    "        + \" \"\n",
    "        + df[\"document\"].apply(\n",
    "            lambda x: re.sub(\n",
    "                \" +\",\n",
    "                \" \",\n",
    "                re.sub(punctuation_to_remove, \" \", x.lower().replace(\"<br />\", \"\")),\n",
    "            ).strip()\n",
    "        )\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__positive i rented i am curious-yellow...</td>\n",
       "      <td>__label__positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__positive i am curious yellow is a ris...</td>\n",
       "      <td>__label__positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__positive if only to avoid making this...</td>\n",
       "      <td>__label__positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__positive this film was probably inspi...</td>\n",
       "      <td>__label__positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__positive oh brother after hearing abo...</td>\n",
       "      <td>__label__positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document              class\n",
       "0  __label__positive i rented i am curious-yellow...  __label__positive\n",
       "1  __label__positive i am curious yellow is a ris...  __label__positive\n",
       "2  __label__positive if only to avoid making this...  __label__positive\n",
       "3  __label__positive this film was probably inspi...  __label__positive\n",
       "4  __label__positive oh brother after hearing abo...  __label__positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.DataFrame(dataset[\"train\"], columns=[\"text\", \"label\"]).rename(\n",
    "    columns={\"text\": \"document\", \"label\": \"class\"}\n",
    ")\n",
    "preprocessed_train = preprocess(train_raw)\n",
    "test_raw = pd.DataFrame(dataset[\"test\"], columns=[\"text\", \"label\"]).rename(\n",
    ")\n",
    "preprocessed_test = preprocess(test_raw)\n",
    "preprocessed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed data to a file\n",
    "preprocessed_train.to_csv(\"data/train.txt\", index=False, header=False)\n",
    "preprocessed_test.to_csv(\"data/test.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt  train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a FastText classifier \n",
    "This classifier have default parameters on the training data, and evaluate it on the test data using accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 5M words\n",
      "Number of words:  116671\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2774038 lr:  0.000000 avg.loss:  0.347542 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.885\n"
     ]
    }
   ],
   "source": [
    "# train fasttext model with default parameters on the preoprocessed train dataset\n",
    "model = ft.train_supervised(input=\"data/train.txt\", label_prefix=\"__label__\")\n",
    "\n",
    "# evaluate the model on the preprocessed test dataset using accuracy\n",
    "print(\"Accuracy: \", model.test(\"data/test.txt\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test data is 0.87812\n",
    "\n",
    "## 3. Use the hyperparameters search functionality of FastText and repeat step 2.\n",
    "\n",
    "- To do so, you'll need to split your training set into a training and a validation set.\n",
    "- Let the model search for 5 minutes (it's the default search time).\n",
    "- Don't forget to shuffle (and stratify) your splits. The dataset has its entry ordered by label (0s first, then 1s). Feeding the classifier one class and then the second can mess with its performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(\n",
    "    preprocessed_train,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=SEED,\n",
    "    stratify=preprocessed_train[\"class\"],\n",
    ")\n",
    "train.to_csv(\"data/train.txt\", index=False, header=False)\n",
    "val.to_csv(\"data/val.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:    9 Best score:  0.905400 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 4M words\n",
      "Number of words:  103843\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1364631 lr:  0.000000 avg.loss:  0.045211 ETA:   0h 0m 0s 93.3% words/sec/thread: 1368873 lr:  0.005722 avg.loss:  0.048109 ETA:   0h 0m 1s\n"
     ]
    }
   ],
   "source": [
    "model_autotune = ft.train_supervised(\n",
    "    input=\"data/train.txt\", autotuneValidationFile=\"data/val.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Look at the differences between the default model and the attributes found with hyperparameters search. How do the two models differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (default model): 0.885\n",
      "Accuracy (Autotuned model): 0.9068\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the preprocessed test dataset using accuracy\n",
    "print(\"Accuracy (default model):\", model.test(\"data/test.txt\")[1])\n",
    "print(\"Accuracy (Autotuned model):\", model_autotune.test(\"data/test.txt\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with default parameters vs autotuned parameters:\n",
    "- Accuracy (default model): 0.87812\n",
    "- Accuracy (Autotuned model): 0.99144\n",
    "\n",
    "We see that the autotuned model is almost 100% right, which is a huge improvement. Let's look at the differences between the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model lr attribute: 0.1\n",
      "Autotuned model lr attribute: 0.08499425639667486\n",
      "\n",
      "Default model loss attribute: loss_name.softmax\n",
      "Autotuned model loss attribute: loss_name.softmax\n",
      "\n",
      "Default model epoch attribute: 5\n",
      "Autotuned model epoch attribute: 100\n",
      "\n",
      "Default model lrUpdateRate attribute: 100\n",
      "Autotuned model lrUpdateRate attribute: 100\n",
      "\n",
      "Default model ws attribute: 5\n",
      "Autotuned model ws attribute: 5\n",
      "\n",
      "Default model neg attribute: 5\n",
      "Autotuned model neg attribute: 5\n",
      "\n",
      "Default model minn attribute: 0\n",
      "Autotuned model minn attribute: 0\n",
      "\n",
      "Default model maxn attribute: 0\n",
      "Autotuned model maxn attribute: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Default model lr attribute:\", model.lr)\n",
    "print(\"Autotuned model lr attribute:\", model_autotune.lr, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model loss attribute:\", model.loss)\n",
    "print(\"Autotuned model loss attribute:\", model_autotune.loss, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model epoch attribute:\", model.epoch)\n",
    "print(\"Autotuned model epoch attribute:\", model_autotune.epoch, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model lrUpdateRate attribute:\", model.lrUpdateRate)\n",
    "print(\n",
    "    \"Autotuned model lrUpdateRate attribute:\", model_autotune.lrUpdateRate, end=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "print(\"Default model ws attribute:\", model.ws)\n",
    "print(\"Autotuned model ws attribute:\", model_autotune.ws, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model neg attribute:\", model.neg)\n",
    "print(\"Autotuned model neg attribute:\", model_autotune.neg, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model minn attribute:\", model.minn)\n",
    "print(\"Autotuned model minn attribute:\", model_autotune.minn, end=\"\\n\\n\")\n",
    "\n",
    "print(\"Default model maxn attribute:\", model.maxn)\n",
    "print(\"Autotuned model maxn attribute:\", model_autotune.maxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap of the values:\n",
    "| Attribute                                  | Default Model | Autotuned Model |\n",
    "| ------------------------------------------ | ------------- | --------------- |\n",
    "| lr                                         | 0.1           | 4.348           |\n",
    "| loss_name                                  | softmax       | softmax         |\n",
    "| epoch                                      | 5             | 14              |\n",
    "| lrUpdateRate                               | 100           | 100             |\n",
    "| ws                                         | 5             | 5               |\n",
    "| neg                                        | 5             | 5               |\n",
    "| Dimension of a lookup vector               | 100           | 66              |\n",
    "| minn                                       | 0             | 3               |\n",
    "| maxn                                       | 0             | 6               |\n",
    "\n",
    "We see that the autotuned model has a very high learning rate (4.35) compared to the default model (0.1). They both use the same loss fonction as well as the same update rate for the learning rate. One of the big difference can also be seen in the number of epoch, where the autotuned model has 3x more epochs than the default model. This could be one of the elements explaining the better accuracy of the autotuned model. Finally, the `minn` and `maxn` attributes go from 0 to 3 and 6 respectively in the autotuned model, which means that the autotuned model uses subword information.\n",
    "\n",
    "## 5. Using the tuned model, take at least 2 wrongly classified examples from the test set, and try explaining why the model failed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First wrongly classified example (pred=__label__negative, label=__label__positive):\n",
      "__label__positive first off let me say if you haven't enjoyed a van damme movie since bloodsport you probably will not like this movie most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are this movie is much better than any of the movies the other action guys segal and dolph have thought about putting out the past few years van damme is good in the movie the movie is only worth watching to van damme fans it is not as good as wake of death which i highly recommend to anyone of likes van damme or in hell but in my opinion it's worth watching it has the same type of feel to it as nowhere to run good fun stuff\n",
      "Second wrongly classified example (pred=__label__negative, label=__label__positive):\n",
      "__label__positive ben rupert grint is a deeply unhappy adolescent the son of his unhappily married parents his father nicholas farrell is a vicar and his mother laura linney is well let's just say she's a somewhat hypocritical soldier in jesus' army it's only when he takes a summer job as an assistant to a foul-mouthed eccentric once-famous and now-forgotten actress evie walton julie walters that he finally finds himself in true 'harold and maude' fashion of course evie is deeply unhappy herself and it's only when these two sad sacks find each other that they can put their mutual misery aside and hit the road to happiness of course it's corny and sentimental and very predictable but it has a hard side to it too and walters who could sleep-walk her way through this sort of thing if she wanted is excellent it's when she puts the craziness to one side and finds the pathos in the character like hitting the bottle and throwing up in the sink that she's at her best the problem is she's the only interesting character in the film and it's not because of the script which doesn't do anybody any favours grint on the other hand isn't just unhappy he's a bit of a bore as well while linney's starched bitch is completely one-dimensional still she's got the english accent off pat the best that can be said for it is that it's mildly enjoyable - with the emphasis on the mildly\n"
     ]
    }
   ],
   "source": [
    "wrongly_classified = []\n",
    "predictions = []\n",
    "for i in range(len(preprocessed_test)):\n",
    "    pred = model.predict(preprocessed_test.iloc[i][\"document\"])[0][0]\n",
    "    if pred != preprocessed_test.iloc[i][\"class\"]:\n",
    "        wrongly_classified.append(preprocessed_test.iloc[i][\"document\"])\n",
    "        predictions.append((pred, preprocessed_test.iloc[i][\"class\"]))\n",
    "    if len(wrongly_classified) == 2:\n",
    "        break\n",
    "\n",
    "print(\n",
    "    f\"First wrongly classified example (pred={predictions[0][0]}, label={predictions[0][1]}):\"\n",
    ")\n",
    "print(wrongly_classified[0])\n",
    "print(\n",
    "    f\"Second wrongly classified example (pred={predictions[1][0]}, label={predictions[1][1]}):\"\n",
    ")\n",
    "print(wrongly_classified[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two wrongly classified examples are the following:\n",
    "1. *first off let me say if you haven't enjoyed a van damme movie since bloodsport you probably will not like this movie most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are this movie is much better than any of the movies the other action guys segal and dolph have thought about putting out the past few years van damme is good in the movie the movie is only worth watching to van damme fans it is not as good as wake of death which i highly recommend to anyone of likes van damme or in hell but in my opinion it's worth watching it has the same type of feel to it as nowhere to run good fun stuff*\n",
    "\n",
    "2. *ben rupert grint is a deeply unhappy adolescent the son of his unhappily married parents his father nicholas farrell is a vicar and his mother laura linney is well let's just say she's a somewhat hypocritical soldier in jesus' army it's only when he takes a summer job as an assistant to a foul-mouthed eccentric once-famous and now-forgotten actress evie walton julie walters that he finally finds himself in true 'harold and maude' fashion of course evie is deeply unhappy herself and it's only when these two sad sacks find each other that they can put their mutual misery aside and hit the road to happiness of course it's corny and sentimental and very predictable but it has a hard side to it too and walters who could sleep-walk her way through this sort of thing if she wanted is excellent it's when she puts the craziness to one side and finds the pathos in the character like hitting the bottle and throwing up in the sink that she's at her best the problem is she's the only interesting character in the film and it's not because of the script which doesn't do anybody any favours grint on the other hand isn't just unhappy he's a bit of a bore as well while linney's starched bitch is completely one-dimensional still she's got the english accent off pat the best that can be said for it is that it's mildly enjoyable - with the emphasis on the mildly*\n",
    "\n",
    "They are both classified as negative, but they are positive.\n",
    "\n",
    "The model could have failed because of some of the same reasons models of the previous labs failed. We can see that the first example uses negative terms to say that people who didn't like this type of movie will probably not like this one, but this is not a negative point towards the movie itself. The second one contains a description of the movie, which seems to have a negative emphasis, but again, this is not related to the movie review itself, so this could be confusing for the classifier. Also, these two examples are mixed reviews, the author didn't enjoy the movie at 100%. The review it still positive but not 100% defending the movie\n",
    "\n",
    "6. Why is it likely that the attributes minn and maxn are at 0 after an hyperparameter search on our data?\n",
    "Hint: on what language are we working?\n",
    "\n",
    "We are working on English, which is a language with a lot of words. This means that the words are not composed of subwords, so the model doesn't need to use subword information to classify the examples. It is possible that during the hyperparameter search, the autotuned model found that the use of character n-grams did not significantly improve the model's performance on the given data, and thus set the `minn` and `maxn` parameters to 0. This could be due to the fact that the text data used for training did not contain significant patterns that could be captured by character n-grams, or that the use of character n-grams led to overfitting on the training data. However, the model ended with these two attributes at 3 and 6, which means that the model did use subword information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
